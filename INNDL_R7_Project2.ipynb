{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " INNDL_R7_Project2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yL18QT8ettV0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "outputId": "e44a3e10-52b5-4921-babb-37e6e9915b01"
      },
      "source": [
        "!pip show tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name: tensorflow\n",
            "Version: 1.15.0\n",
            "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
            "Home-page: https://www.tensorflow.org/\n",
            "Author: Google Inc.\n",
            "Author-email: packages@tensorflow.org\n",
            "License: Apache 2.0\n",
            "Location: /usr/local/lib/python3.6/dist-packages\n",
            "Requires: tensorflow-estimator, tensorboard, grpcio, numpy, wrapt, google-pasta, astor, opt-einsum, gast, termcolor, absl-py, wheel, keras-preprocessing, keras-applications, protobuf, six\n",
            "Required-by: stable-baselines, magenta, fancyimpute\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKbpc0aWw3lo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff23e6cf-73ba-46ad-f3b8-6ac5c0efc0e6"
      },
      "source": [
        "# For the current version: \n",
        "!pip install --upgrade tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 76kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.4)\n",
            "Requirement already satisfied, skipping upgrade: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 45.9MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 26.6MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/36/f8/84b5771faec3eba9fe0c91c8c5896364a8ba08852c0dea5ad2025026dd95/google_auth-1.10.0-py2.py3-none-any.whl (76kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (42.0.2)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.2.7)\n",
            "Requirement already satisfied, skipping upgrade: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.3.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow) (0.4.8)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.1.0)\n",
            "\u001b[31mERROR: tensorboard 2.0.2 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.10.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-auth, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: google-auth 1.4.2\n",
            "    Uninstalling google-auth-1.4.2:\n",
            "      Successfully uninstalled google-auth-1.4.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed google-auth-1.10.0 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSvQf6_uvI4L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "2f977240-a885-43c2-d6f4-47c2b1a0904e"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H08rAKM9wVmq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import h5py\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qfl9FNvePQhE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "h5f = h5py.File(\"/content/drive/My Drive/Documents/Project-case_study-2/SVHN_single_grey1.h5\",'r')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AAP8n4dHlGSU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "5d727d8e-3b28-4b0e-8553-d691b3d6faf6"
      },
      "source": [
        "print(\"Keys: %s\" % h5f.keys())\n",
        "group_keys = list(h5f.keys())\n",
        "\n",
        "# Get the data\n",
        "for i in range(len(group_keys)):\n",
        "  print(group_keys[i], len(list(h5f[group_keys[i]])))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keys: KeysView(<HDF5 file \"SVHN_single_grey1.h5\" (mode r)>)\n",
            "X_test 18000\n",
            "X_train 42000\n",
            "X_val 60000\n",
            "y_test 18000\n",
            "y_train 42000\n",
            "y_val 60000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UU747e1JREoj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "b76c1fec-e8bc-473c-bea1-a9618dc464ae"
      },
      "source": [
        "# Load the training, test and validation set\n",
        "X_train = h5f['X_train'][:]\n",
        "y_train = h5f['y_train'][:]\n",
        "X_test = h5f['X_test'][:]\n",
        "y_test = h5f['y_test'][:]\n",
        "X_val = h5f['X_val'][:]\n",
        "y_val = h5f['y_val'][:]\n",
        "\n",
        "# Close this file\n",
        "h5f.close()\n",
        "\n",
        "print('Training set', X_train.shape, y_train.shape)\n",
        "print('Validation set', X_val.shape, y_val.shape)\n",
        "print('Test set', X_test.shape, y_test.shape)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set (42000, 32, 32) (42000,)\n",
            "Validation set (60000, 32, 32) (60000,)\n",
            "Test set (18000, 32, 32) (18000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDpb8RyNyjji",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "X_test1 = np.asarray(X_test).reshape(18000, 32*32)\n",
        "X_train1 = np.asarray(X_train).reshape(42000, 32*32)\n",
        "X_val1 = np.asarray(X_val).reshape(60000, 32*32)\n",
        "y_test1 = np.asarray(y_test).reshape(18000, 1)\n",
        "y_train1 = np.asarray(y_train).reshape(42000, 1)\n",
        "y_val1 = np.asarray(y_val).reshape(60000, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyL25ucUi2EW",
        "colab_type": "text"
      },
      "source": [
        "KNN Classical Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bak6M2Rso-nE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "c39d4a48-2dfc-4b36-ce7d-48c16a374507"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train1, y_train1)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
              "                     metric_params=None, n_jobs=None, n_neighbors=3, p=2,\n",
              "                     weights='uniform')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cznU10PVpHkR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8a62e9b9-c5d4-4e54-9598-358daa4d540b"
      },
      "source": [
        "y_pred = knn.predict(X_val1)\n",
        "print(accuracy_score(y_val1, y_pred))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6283166666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xzDxNCeShZs8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "065ede4d-384a-45e6-b17e-32d915fdd296"
      },
      "source": [
        "y_pred = knn.predict(X_val1)\n",
        "print(accuracy_score(y_val1, y_pred))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6283166666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFPT1pTU3UtI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "08316041-180b-4724-8ce8-4396fe3d2de2"
      },
      "source": [
        "y_pred_test = knn.predict(X_test1)\n",
        "print(accuracy_score(y_test1, y_pred_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4617777777777778\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkpvz02SpWn8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "e347dbbe-4d94-4cde-ffef-f8677622a4dd"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.confusion_matrix(y_test1, y_pred_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1234   73   58   66   63   43  106   22   68   81]\n",
            " [ 135 1306  104   81   81   34   23   42   12   10]\n",
            " [ 154  285  967  112   55   29   25   97   33   46]\n",
            " [ 183  302  206  648   67  134   39   33   61   46]\n",
            " [ 200  303   65   76 1016   31   50   13   36   22]\n",
            " [ 248  192  116  326   76  561   99   16   80   54]\n",
            " [ 432  156   80  100  136  156  575    5  169   23]\n",
            " [ 162  283  162   89   34   25   21  987   13   32]\n",
            " [ 386  162  109  209   95  144  184   11  449   63]\n",
            " [ 460  168  124  137   72   84   75   37   78  569]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6EdA7xjZp8Yf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "894d5bca-2586-4df2-e74b-b488fbfac21e"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5', 'class 6', 'class 7', 'class 8', 'class 9']\n",
        "print(classification_report(y_test1, y_pred_test, target_names=target_names))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.34      0.68      0.46      1814\n",
            "     class 1       0.40      0.71      0.52      1828\n",
            "     class 2       0.49      0.54      0.51      1803\n",
            "     class 3       0.35      0.38      0.36      1719\n",
            "     class 4       0.60      0.56      0.58      1812\n",
            "     class 5       0.45      0.32      0.37      1768\n",
            "     class 6       0.48      0.31      0.38      1832\n",
            "     class 7       0.78      0.55      0.64      1808\n",
            "     class 8       0.45      0.25      0.32      1812\n",
            "     class 9       0.60      0.32      0.41      1804\n",
            "\n",
            "    accuracy                           0.46     18000\n",
            "   macro avg       0.49      0.46      0.46     18000\n",
            "weighted avg       0.50      0.46      0.46     18000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfOQq8FSDSTK",
        "colab_type": "text"
      },
      "source": [
        "Implement a Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9z0AsxzP-kke",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Reshape, BatchNormalization\n",
        "from tensorflow.keras.layers import Convolution2D, MaxPooling2D"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFRnBABJ_fri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#ONE HOT VECTOR CONVERSION\n",
        "y_train_c = tensorflow.keras.utils.to_categorical(y_train, num_classes=10)\n",
        "y_test_c = tensorflow.keras.utils.to_categorical(y_test, num_classes=10)\n",
        "y_val_c = tensorflow.keras.utils.to_categorical(y_val, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbgKoIII_lpP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "48aac31b-bfa6-48cf-8cfb-11458e9c4197"
      },
      "source": [
        "print(X_train.shape, X_val.shape, X_test.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 32, 32) (60000, 32, 32) (18000, 32, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nv0a7qCy_w4d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a8e39998-67bd-4805-e14a-bfcc25fd4e73"
      },
      "source": [
        "X_train_c = np.asarray(X_train).reshape(X_train.shape[0],X_train.shape[1], X_train.shape[2],1)\n",
        "X_test_c = np.asarray(X_test).reshape(X_test.shape[0],X_test.shape[1], X_test.shape[2],1)\n",
        "X_val_c = np.asarray(X_val).reshape(X_val.shape[0],X_val.shape[1], X_val.shape[2],1)\n",
        "\n",
        "print(type(X_train_c), X_train_c.shape)\n",
        "print(type(X_test_c), X_test_c.shape)\n",
        "print(type(X_val_c), X_val_c.shape)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> (42000, 32, 32, 1)\n",
            "<class 'numpy.ndarray'> (18000, 32, 32, 1)\n",
            "<class 'numpy.ndarray'> (60000, 32, 32, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZ7i7fVl_7wn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Reshape((1024,),input_shape=(32,32,1,)))\n",
        "model.add(BatchNormalization())\n",
        "\n",
        "model.add(Dense(200, activation='relu', name='Layer_1'))\n",
        "model.add(Dense(100, activation='relu', name='Layer_2'))\n",
        "\n",
        "model.add(Dense(60, activation='relu', name='Layer_3'))\n",
        "model.add(Dense(30, activation='relu', name='Layer_4'))\n",
        "\n",
        "model.add(Dense(10, activation='softmax', name='Output'))\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RJceBclA9zz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f3d58377-ff8e-42d5-812a-3d4541cb92db"
      },
      "source": [
        "model.fit(X_train_c,y_train_c,          \n",
        "          validation_data=(X_val_c,y_val_c),\n",
        "          epochs=30,\n",
        "          batch_size=32)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 60000 samples\n",
            "Epoch 1/30\n",
            "42000/42000 [==============================] - 14s 327us/sample - loss: 1.4404 - accuracy: 0.5146 - val_loss: 0.9651 - val_accuracy: 0.7002\n",
            "Epoch 2/30\n",
            "42000/42000 [==============================] - 12s 284us/sample - loss: 1.0057 - accuracy: 0.6793 - val_loss: 0.7930 - val_accuracy: 0.7529\n",
            "Epoch 3/30\n",
            "42000/42000 [==============================] - 12s 284us/sample - loss: 0.8642 - accuracy: 0.7264 - val_loss: 0.7129 - val_accuracy: 0.7769\n",
            "Epoch 4/30\n",
            "42000/42000 [==============================] - 12s 287us/sample - loss: 0.7911 - accuracy: 0.7510 - val_loss: 0.6367 - val_accuracy: 0.8043\n",
            "Epoch 5/30\n",
            "42000/42000 [==============================] - 13s 307us/sample - loss: 0.7393 - accuracy: 0.7667 - val_loss: 0.5911 - val_accuracy: 0.8213\n",
            "Epoch 6/30\n",
            "42000/42000 [==============================] - 13s 304us/sample - loss: 0.6967 - accuracy: 0.7808 - val_loss: 0.5595 - val_accuracy: 0.8279\n",
            "Epoch 7/30\n",
            "42000/42000 [==============================] - 12s 288us/sample - loss: 0.6560 - accuracy: 0.7924 - val_loss: 0.5359 - val_accuracy: 0.8367\n",
            "Epoch 8/30\n",
            "42000/42000 [==============================] - 12s 290us/sample - loss: 0.6349 - accuracy: 0.7992 - val_loss: 0.4928 - val_accuracy: 0.8505\n",
            "Epoch 9/30\n",
            "42000/42000 [==============================] - 12s 286us/sample - loss: 0.6090 - accuracy: 0.8063 - val_loss: 0.4927 - val_accuracy: 0.8502\n",
            "Epoch 10/30\n",
            "42000/42000 [==============================] - 12s 287us/sample - loss: 0.5895 - accuracy: 0.8129 - val_loss: 0.4807 - val_accuracy: 0.8542\n",
            "Epoch 11/30\n",
            "42000/42000 [==============================] - 12s 286us/sample - loss: 0.5777 - accuracy: 0.8153 - val_loss: 0.4792 - val_accuracy: 0.8539\n",
            "Epoch 12/30\n",
            "42000/42000 [==============================] - 12s 292us/sample - loss: 0.5631 - accuracy: 0.8213 - val_loss: 0.4615 - val_accuracy: 0.8573\n",
            "Epoch 13/30\n",
            "42000/42000 [==============================] - 12s 291us/sample - loss: 0.5446 - accuracy: 0.8257 - val_loss: 0.4436 - val_accuracy: 0.8655\n",
            "Epoch 14/30\n",
            "42000/42000 [==============================] - 12s 289us/sample - loss: 0.5346 - accuracy: 0.8315 - val_loss: 0.4432 - val_accuracy: 0.8645\n",
            "Epoch 15/30\n",
            "42000/42000 [==============================] - 12s 292us/sample - loss: 0.5163 - accuracy: 0.8362 - val_loss: 0.4425 - val_accuracy: 0.8659\n",
            "Epoch 16/30\n",
            "42000/42000 [==============================] - 12s 292us/sample - loss: 0.5098 - accuracy: 0.8364 - val_loss: 0.4077 - val_accuracy: 0.8764\n",
            "Epoch 17/30\n",
            "42000/42000 [==============================] - 13s 298us/sample - loss: 0.5050 - accuracy: 0.8374 - val_loss: 0.3930 - val_accuracy: 0.8819\n",
            "Epoch 18/30\n",
            "42000/42000 [==============================] - 12s 292us/sample - loss: 0.4930 - accuracy: 0.8422 - val_loss: 0.4043 - val_accuracy: 0.8791\n",
            "Epoch 19/30\n",
            "42000/42000 [==============================] - 12s 290us/sample - loss: 0.4791 - accuracy: 0.8469 - val_loss: 0.3858 - val_accuracy: 0.8840\n",
            "Epoch 20/30\n",
            "42000/42000 [==============================] - 12s 287us/sample - loss: 0.4787 - accuracy: 0.8486 - val_loss: 0.3787 - val_accuracy: 0.8875\n",
            "Epoch 21/30\n",
            "42000/42000 [==============================] - 12s 289us/sample - loss: 0.4716 - accuracy: 0.8506 - val_loss: 0.3819 - val_accuracy: 0.8851\n",
            "Epoch 22/30\n",
            "42000/42000 [==============================] - 12s 288us/sample - loss: 0.4651 - accuracy: 0.8523 - val_loss: 0.3918 - val_accuracy: 0.8813\n",
            "Epoch 23/30\n",
            "42000/42000 [==============================] - 12s 292us/sample - loss: 0.4635 - accuracy: 0.8505 - val_loss: 0.3663 - val_accuracy: 0.8897\n",
            "Epoch 24/30\n",
            "42000/42000 [==============================] - 12s 287us/sample - loss: 0.4497 - accuracy: 0.8552 - val_loss: 0.3675 - val_accuracy: 0.8911\n",
            "Epoch 25/30\n",
            "42000/42000 [==============================] - 12s 288us/sample - loss: 0.4457 - accuracy: 0.8567 - val_loss: 0.3653 - val_accuracy: 0.8925\n",
            "Epoch 26/30\n",
            "42000/42000 [==============================] - 12s 292us/sample - loss: 0.4351 - accuracy: 0.8607 - val_loss: 0.3559 - val_accuracy: 0.8943\n",
            "Epoch 27/30\n",
            "42000/42000 [==============================] - 12s 291us/sample - loss: 0.4373 - accuracy: 0.8612 - val_loss: 0.3721 - val_accuracy: 0.8880\n",
            "Epoch 28/30\n",
            "42000/42000 [==============================] - 12s 293us/sample - loss: 0.4283 - accuracy: 0.8653 - val_loss: 0.3562 - val_accuracy: 0.8938\n",
            "Epoch 29/30\n",
            "42000/42000 [==============================] - 12s 290us/sample - loss: 0.4285 - accuracy: 0.8640 - val_loss: 0.3681 - val_accuracy: 0.8898\n",
            "Epoch 30/30\n",
            "42000/42000 [==============================] - 12s 293us/sample - loss: 0.4178 - accuracy: 0.8660 - val_loss: 0.3435 - val_accuracy: 0.8990\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f147721f240>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yIvUZloDAyc",
        "colab_type": "text"
      },
      "source": [
        "Implement backpropagation (cost stochastic gradient descent, cross entropy loss, cost functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kf2CFiC3DN8f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee5c7706-be90-4620-88c8-a357ebc6bacb"
      },
      "source": [
        "model1 = Sequential()\n",
        "model1.add(Reshape((1024,),input_shape=(32,32,1,)))\n",
        "model1.add(BatchNormalization())\n",
        "\n",
        "model1.add(Dense(200, activation='relu', name='Layer_1'))\n",
        "model1.add(Dense(100, activation='relu', name='Layer_2'))\n",
        "\n",
        "model1.add(Dense(60, activation='relu', name='Layer_3'))\n",
        "model1.add(Dense(30, activation='relu', name='Layer_4'))\n",
        "\n",
        "model1.add(Dense(10, activation='softmax', name='Output'))\n",
        "\n",
        "sgd =  optimizers.Adam(lr=0.002, beta_1=0.9, beta_2=0.999) # with decay values\n",
        "\n",
        "model1.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "model1.fit(X_train_c,y_train_c,          \n",
        "          validation_data=(X_val_c,y_val_c),\n",
        "          epochs=30,\n",
        "          batch_size=32)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 42000 samples, validate on 60000 samples\n",
            "Epoch 1/30\n",
            "42000/42000 [==============================] - 14s 324us/sample - loss: 1.4894 - accuracy: 0.4970 - val_loss: 1.0085 - val_accuracy: 0.6855\n",
            "Epoch 2/30\n",
            "42000/42000 [==============================] - 13s 301us/sample - loss: 1.0425 - accuracy: 0.6701 - val_loss: 0.8496 - val_accuracy: 0.7395\n",
            "Epoch 3/30\n",
            "42000/42000 [==============================] - 13s 304us/sample - loss: 0.9119 - accuracy: 0.7137 - val_loss: 0.7537 - val_accuracy: 0.7686\n",
            "Epoch 4/30\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 0.8365 - accuracy: 0.7398 - val_loss: 0.7051 - val_accuracy: 0.7882\n",
            "Epoch 5/30\n",
            "42000/42000 [==============================] - 12s 297us/sample - loss: 0.7837 - accuracy: 0.7555 - val_loss: 0.6094 - val_accuracy: 0.8137\n",
            "Epoch 6/30\n",
            "42000/42000 [==============================] - 12s 298us/sample - loss: 0.7428 - accuracy: 0.7671 - val_loss: 0.6064 - val_accuracy: 0.8191\n",
            "Epoch 7/30\n",
            "42000/42000 [==============================] - 13s 302us/sample - loss: 0.7103 - accuracy: 0.7795 - val_loss: 0.5692 - val_accuracy: 0.8280\n",
            "Epoch 8/30\n",
            "42000/42000 [==============================] - 13s 307us/sample - loss: 0.6808 - accuracy: 0.7880 - val_loss: 0.5571 - val_accuracy: 0.8311\n",
            "Epoch 9/30\n",
            "42000/42000 [==============================] - 13s 303us/sample - loss: 0.6650 - accuracy: 0.7941 - val_loss: 0.5491 - val_accuracy: 0.8288\n",
            "Epoch 10/30\n",
            "42000/42000 [==============================] - 13s 306us/sample - loss: 0.6482 - accuracy: 0.7980 - val_loss: 0.5344 - val_accuracy: 0.8368\n",
            "Epoch 11/30\n",
            "42000/42000 [==============================] - 13s 310us/sample - loss: 0.6301 - accuracy: 0.8031 - val_loss: 0.5304 - val_accuracy: 0.8395\n",
            "Epoch 12/30\n",
            "42000/42000 [==============================] - 13s 307us/sample - loss: 0.6124 - accuracy: 0.8080 - val_loss: 0.5024 - val_accuracy: 0.8461\n",
            "Epoch 13/30\n",
            "42000/42000 [==============================] - 13s 318us/sample - loss: 0.6051 - accuracy: 0.8120 - val_loss: 0.4849 - val_accuracy: 0.8539\n",
            "Epoch 14/30\n",
            "42000/42000 [==============================] - 13s 307us/sample - loss: 0.5932 - accuracy: 0.8149 - val_loss: 0.4714 - val_accuracy: 0.8591\n",
            "Epoch 15/30\n",
            "42000/42000 [==============================] - 13s 308us/sample - loss: 0.5793 - accuracy: 0.8196 - val_loss: 0.4522 - val_accuracy: 0.8648\n",
            "Epoch 16/30\n",
            "42000/42000 [==============================] - 13s 308us/sample - loss: 0.5635 - accuracy: 0.8256 - val_loss: 0.4761 - val_accuracy: 0.8597\n",
            "Epoch 17/30\n",
            "42000/42000 [==============================] - 13s 309us/sample - loss: 0.5624 - accuracy: 0.8254 - val_loss: 0.4563 - val_accuracy: 0.8610\n",
            "Epoch 18/30\n",
            "42000/42000 [==============================] - 13s 311us/sample - loss: 0.5515 - accuracy: 0.8268 - val_loss: 0.4596 - val_accuracy: 0.8622\n",
            "Epoch 19/30\n",
            "42000/42000 [==============================] - 13s 311us/sample - loss: 0.5434 - accuracy: 0.8326 - val_loss: 0.4588 - val_accuracy: 0.8614\n",
            "Epoch 20/30\n",
            "42000/42000 [==============================] - 13s 313us/sample - loss: 0.5405 - accuracy: 0.8320 - val_loss: 0.4147 - val_accuracy: 0.8762\n",
            "Epoch 21/30\n",
            "42000/42000 [==============================] - 13s 310us/sample - loss: 0.5323 - accuracy: 0.8330 - val_loss: 0.4308 - val_accuracy: 0.8723\n",
            "Epoch 22/30\n",
            "42000/42000 [==============================] - 13s 307us/sample - loss: 0.5269 - accuracy: 0.8354 - val_loss: 0.4224 - val_accuracy: 0.8741\n",
            "Epoch 23/30\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 0.5222 - accuracy: 0.8392 - val_loss: 0.4170 - val_accuracy: 0.8791\n",
            "Epoch 24/30\n",
            "42000/42000 [==============================] - 13s 310us/sample - loss: 0.5107 - accuracy: 0.8427 - val_loss: 0.4197 - val_accuracy: 0.8742\n",
            "Epoch 25/30\n",
            "42000/42000 [==============================] - 13s 316us/sample - loss: 0.5073 - accuracy: 0.8432 - val_loss: 0.4105 - val_accuracy: 0.8783\n",
            "Epoch 26/30\n",
            "42000/42000 [==============================] - 13s 311us/sample - loss: 0.5056 - accuracy: 0.8431 - val_loss: 0.4183 - val_accuracy: 0.8760\n",
            "Epoch 27/30\n",
            "42000/42000 [==============================] - 13s 319us/sample - loss: 0.5010 - accuracy: 0.8453 - val_loss: 0.3905 - val_accuracy: 0.8855\n",
            "Epoch 28/30\n",
            "42000/42000 [==============================] - 14s 337us/sample - loss: 0.4878 - accuracy: 0.8491 - val_loss: 0.4038 - val_accuracy: 0.8790\n",
            "Epoch 29/30\n",
            "42000/42000 [==============================] - 14s 331us/sample - loss: 0.4837 - accuracy: 0.8485 - val_loss: 0.4014 - val_accuracy: 0.8816\n",
            "Epoch 30/30\n",
            "42000/42000 [==============================] - 13s 311us/sample - loss: 0.4842 - accuracy: 0.8490 - val_loss: 0.3833 - val_accuracy: 0.8866\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1474fef2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2qcAlY6FcG8",
        "colab_type": "text"
      },
      "source": [
        "We observe that with decay in this case, validation accuracy has reduced - in model1. We will continue to use the first model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za2MiZrwFkZ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test_c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AttEhsmZHski",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "77616708-4d85-444c-b8d9-560549b0df59"
      },
      "source": [
        "max_y_pred = np.zeros_like(y_pred)\n",
        "max_y_pred[np.arange(len(y_pred)), y_pred.argmax(1)] = 1\n",
        "\n",
        "max_y_pred"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 1., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 1.],\n",
              "       [0., 0., 1., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9TunCfSH32L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_classes = [np.argmax(y, axis=None, out=None) for y in max_y_pred]\n",
        "y_test_classes = [np.argmax(y, axis=None, out=None) for y in y_test_c]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mp_BcuoDH9sC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "cbb0d9a3-6ff3-4332-8de4-94e3cee8962f"
      },
      "source": [
        "\n",
        "print(y_test_c)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 1.]\n",
            " [0. 0. 1. ... 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tF2_OLjiIIJl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "369695f6-1077-4fd1-95ef-2c858ee7a6dd"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test_classes, y_pred_classes)\n",
        "print(cm)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1680   17    4   11   19    3   14   22   15   29]\n",
            " [ 106 1523   10   18   47   13    6   73   25    7]\n",
            " [  54   35 1515   40   17   12    7   62   20   41]\n",
            " [  50   41   23 1307   19  129   15   43   57   35]\n",
            " [  44   64   22    6 1577   13   19   16   10   41]\n",
            " [  24   20    8   63    9 1493   71   14   45   21]\n",
            " [  97   25   11   17   38   74 1478   17   63   12]\n",
            " [  41   59   21   17    7   12    6 1621   12   12]\n",
            " [  76   45   28   22   31   26   92   16 1422   54]\n",
            " [ 137   27   18   26   20   49   11   33   36 1447]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaP3WEtrIP8x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "outputId": "44d0084e-e461-423d-83f4-17eca448c837"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names = ['class 0', 'class 1', 'class 2', 'class 3', 'class 4', 'class 5', 'class 6', 'class 7', 'class 8', 'class 9']\n",
        "print(classification_report(y_test_classes, y_pred_classes, target_names=target_names))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     class 0       0.73      0.93      0.81      1814\n",
            "     class 1       0.82      0.83      0.83      1828\n",
            "     class 2       0.91      0.84      0.87      1803\n",
            "     class 3       0.86      0.76      0.81      1719\n",
            "     class 4       0.88      0.87      0.88      1812\n",
            "     class 5       0.82      0.84      0.83      1768\n",
            "     class 6       0.86      0.81      0.83      1832\n",
            "     class 7       0.85      0.90      0.87      1808\n",
            "     class 8       0.83      0.78      0.81      1812\n",
            "     class 9       0.85      0.80      0.83      1804\n",
            "\n",
            "    accuracy                           0.84     18000\n",
            "   macro avg       0.84      0.84      0.84     18000\n",
            "weighted avg       0.84      0.84      0.84     18000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYWEofYOIjy6",
        "colab_type": "text"
      },
      "source": [
        "Conclusion:\n",
        "\n",
        "The classicial KNN trained model takes alot of time - approxiamtely 2 hrs and delivers lower accuracy scores. The image data is a bigger training set and distance calculations in KNN seem to take more time. In a Neural Network method, the prior layer and nodes feed into next layer which is must faster and optimized,and also the modeler has a control on Activation functions- type and number of neurons , learning rates , etc. Since the NN is much faster various trials with the network can be made to tune the model for higher accuracy."
      ]
    }
  ]
}